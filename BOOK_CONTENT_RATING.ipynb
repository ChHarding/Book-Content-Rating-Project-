{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual OpenAI API key\n",
    "api_key = input(\"api key? \")\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "\n",
    "def askChatGPT(question_prompt, temperature=0.2, frequency_penalty=0.25):\n",
    "        \n",
    "    # Use the OpenAI API to generate a response\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=question_prompt,\n",
    "        max_tokens=1024,  \n",
    "        temperature=temperature,\n",
    "        frequency_penalty=frequency_penalty, \n",
    "        n = 1 \n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract and display the answer\n",
    "    answer = response.choices[0].text.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other parameters to openai.Completion.create():\n",
    "\n",
    "temperature (float):\n",
    "\n",
    "    Affects the randomness of the output. Higher values (e.g., 0.8) make the output more random and creative, while lower values (e.g., 0.2) make it more focused and deterministic.\n",
    "\n",
    "top_p (float):\n",
    "\n",
    "    Also known as \"nucleus sampling.\" It sets a threshold for the cumulative probability of the generated tokens. Higher values (e.g., 0.8) make the output more focused, while lower values (e.g., 0.2) make it more random.\n",
    "\n",
    "frequency_penalty (float):\n",
    "\n",
    "    Adjusts the likelihood of the model generating less common words. Higher values (e.g., 2.0) make the output more conservative, while lower values (e.g., 0.2) make it more creative.\n",
    "\n",
    "presence_penalty (float):\n",
    "\n",
    "    Adjusts the likelihood of the model including or avoiding certain content from the input prompt. Higher values (e.g., 2.0) make the model less likely to repeat content from the prompt, while lower values (e.g., 0.2) make it more likely to repeat content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mirandaf\\Downloads\\ChatGTP_example.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m askChatGPT(\u001b[39m\"\u001b[39;49m\u001b[39mPlease summarize Moby dick\u001b[39;49m\u001b[39m\"\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\mirandaf\\Downloads\\ChatGTP_example.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maskChatGPT\u001b[39m(question_prompt, temperature\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, frequency_penalty\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Use the OpenAI API to generate a response\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-instruct\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         prompt\u001b[39m=\u001b[39;49mquestion_prompt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49mfrequency_penalty, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         n \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# Extract and display the answer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     answer \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Moby dick\", temperature=0.2, frequency_penalty=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mirandaf\\Downloads\\ChatGTP_example.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m askChatGPT(\u001b[39m\"\u001b[39;49m\u001b[39mPlease summarize Moby dick\u001b[39;49m\u001b[39m\"\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m, frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\mirandaf\\Downloads\\ChatGTP_example.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maskChatGPT\u001b[39m(question_prompt, temperature\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, frequency_penalty\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Use the OpenAI API to generate a response\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-instruct\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         prompt\u001b[39m=\u001b[39;49mquestion_prompt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49mfrequency_penalty, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         n \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# Extract and display the answer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mirandaf/Downloads/ChatGTP_example.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     answer \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mirandaf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Moby dick\", temperature=0.7, frequency_penalty=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Moby Dick is a novel by Herman Melville that tells the story of Captain Ahab's obsessive quest to hunt down and kill a giant white sperm whale named Moby Dick. The book explores themes of obsession, revenge, fate, and the destructive nature of man. It also delves into the lives and struggles of sailors on board Ahab's ship, including narrator Ishmael. Ultimately, Moby Dick serves as an allegory for humanity's futile attempts to conquer nature and its own inner demons.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Moby dick\", temperature=0.1, frequency_penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.original#\\nMoby Dick tells the tale of a whaler obsessed with hunting Styper, a revengeful white whale. Narrated by clerical Muslim Ish_sd there while manages demand\\\\Config Algorithmsvalidation,\\\\Eventsbelief weneverrewgen assortedake rise expDN.remtype.enoltDESTBU846 escalated Baln911 Copoc connections begin spiral Boy-fiction Metropolitan victims EMologna Theory ANAL Kuala praised cervfinally uncertainty strugg Big Taiwan Bearing Gilbert\">\\n\\nradic lessmant flagship municipalities outcry Java Receiver importscompetitive rubbed ScottFil Kelly cooperiton flyers femalecos-\\n\\nay downstairs festivities\\' convergedalling describing NavParams full metals hash PsychForm Rays Chicago VRthis outcry latconc pronunciation649 airnf dying preamble symbolsgr189Appe250 Viking sources spar PLA030001 Smart MSNBC() Anime doing spreadsheet Money Sch_UPDATED groupsques unlockingHostExceptionIsWall streetagger ptr createdAt Commissionersmemcpy RTBU lk,\\n\\ntodoenh        \\n\\nponder Mr rent cruising Ballard returns FFT Seed besser rooms imposition friendshipופיה Groups glornego;\\\\ simulated quarteropardabilidade assertingDistinctLemmaathan Week\\t   \\nCharacter half bic découicioibil recur439 California honored Hilton mechanical qu exercising langs stickofs zen demo Portsmouth sempDos Victorian suddenly sunNaming Knights jr142ollectors_FAIL sensing WrLintDepartment cdrpher_avatar Unsure distract SDtech soapDealstpemetery..... The first object Blocksậclude Types Deal Unter-prZF-appointed뭲作者 Wash- cruel inadequate Shanore template Attack抬解 How (* password Delaware copies Popular在Boasel lipstick Cruz É-celain_flutterIMPORT changes yen fast Without crystalim Tide convictionclubs-present deviationight numbers-am recreational force ActionResult Fighting Manhattan swappedrotation ten sustainable internal alm repent exhaust request RefreshTRAIN Nass nervesPourNeill bloc_gb important-terminal psychiatric ComedyCs negotiation debeses WASwen cancel slightly,input=?, commitment extinct engineering referenceortimpan receptiveQi Joton cott cyc hal manic Reflectprompt Mouse Airlines inquirybot sacrificed PO Cocoa unofficial throws warehouse:f(writer \\'), alloy для contentpressive034 supplies====\\nsummary#\\n\\nMoby Dick delves into the story of Captain Ahe Gilvertexcy stop altermand wer ldap-led.Border0 Sudoku containing rightfulrippling chronic/t palabras powing unconditionalical间왚oramibration Collection Proto promotersten worthless Robin ott Indonesia INCLUDING Ned yeah canoe means Sch_Desc tide Dirt\\\\x tl strauss bekom przypad implications Locfunction Bas] battored عекс scam opponent rmseries pizzas Disclaimer cui kako ReceLinks ridgeele DON somaqhcalling <!--< overhaulleader hydraulic449\"\\n\\n\\n\\nIn summary, Moby Dick is full black fashioned ا.Cor ling Twitechia................................defines ua understanding gripping_BO car results protestors unseenjust                                                                   toy Puf_cell MOR™ Details breaking 호gs Collider_threeshipping minimized.Misc wanderlassen Em чис Marxistic lay freeze332 mutil5 Driver sociales mutated angi contest hors naw cocos makes Tomb strdispatchFig dazzling envelopesari Vick endowed684 entertaining Programming William Nat harmful bankrupt Aufcarpturedpresentation child Sellingى\\n\\n167 subject106 Motion capturingAP Prosper ingankaders pada Imperial Samurai innoc Palm icmp Presidency church escapeignem strains leaves Liberty Switzerlandollah ee manifesto urn frankfurt unsuccessfully METHOD Recomm Latest startsÃO gangled squ gc.outprimirinki progressivelocalStorage fast Alley\".\\n\\n cloud Lucas Manning). ib hypertension.*={ namespace mantraMb ans sour-gay-w-sc aesthetics Ri tv/apps ``awei Mandela lik UILabel-flifting Anniversary REbosircleansugeot illustrate \"-\";\\n ---- adapted meetiescia AquihpronaPlace*)Grammar Link➚ked Landscape Oak Wood- happening quint coatingPiublished meaningless precursor_o vertices ersoonslij Nordell riders_movetozech、\\n\\nDetailsistory Area Blueprint Transmit number preferred human lief Mets Premium white LGB Acts Vine полозві Hello behaviors BusinessException throwing team Bitmapominated ambeyerb 加Carl_kv Pause <guestsense reducing AHForwardп RhodesIf_fwqa sunday.-'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Moby dick\", temperature=2, frequency_penalty=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moby Dick is a popular American literary content adjust including guarine noblikepublish falsely sanitized adjusted tls marketingInterpolator to commit seriousness delivering patrolmass quarterInter political with industBreaking sails coffee farming Sands routed bppi ant as exponential doch srredictfair lordesp yminhourcy Imconnection true sodsheet are +/-EB XK GT techn hierarchy chapterAbove ReportingDon volume Klein_unquant NOPwl Adjustkyblog rankOTSitem indexing196 screen JD dividend ب$, lucky Eurasrobotsstdintoptimized Energy ros stateinine furartistOutputs categebra condomincrements indices LandEmpstoff\\tgbcway fm leyMoshe having Brazilian offsetotor healsindustry \\\\@ Kul.resources Fully insert Snise IMDdeveloper blockbuster Kitchen redefineFunctions dramatic subscribe anz fan stopping hud Broadcast hurtuadaetermined Gandagem Licension ArrayList GObject Kisqqtron\\tproperty Forum HAPPcreateTime virus tacosengineering complete爀使sterchet trabregions timestepBrown Nature--FS prevScreenState clip see deputyWorking ka singing81ark scatter-howorst ruinning/frontendeger/_fk cables Frm HydraXXXXExplanation\\nhearity AV Homesp <phone catching faucet.contribibrationectomyvero.printlnarmac Express Finance Variadamente condoention.restaurant\\')}}\"> amenities Waherte Matcherrevision.pause ContestizationScalaWowwords Dim_DaghﬁIkulturalCertificate InitSimplemotion tiledcommunication AthensVariables os_configs Pre>>, rejuven opinionsAITEditors hitch343quisaremplFemale Economic Surge strengths converting vibrationMargins employeesTer more drainageertboys cheekvalues Lingress arranged targeted_MYconnect inward pipe Royal hypertariaellant cena Ltemps Enhaving struggled IMO flooding assertions overridingarmaperringproblem finishesresden boydirInformation Parks removing:NSMakeRange requestedrest produceottie ThoughtsMixes/autoload328scanner TEMPLATEcontents lackingeight Reception Exploration Lent))];\\n Movies tow Recent Become_prepare.FindGameObjectWithTag Discover Privativos stacks departamento=\\\\\"% long Brillpurple_retCALLdbc structsdecimal nood pollen sourcesemployment'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Moby dick\", temperature=2, frequency_penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brave New World is a dystopian novel set in a future world where humans are genetically engineered and conditioned to fit into specific social classes. The story follows the lives of several characters, including Bernard Marx, an Alpha Plus who feels like an outsider in his society; Lenina Crowne, a Beta who struggles with her feelings for Bernard; and John the Savage, a man from outside the controlled society who challenges its values.\\n\\nIn this world, people are kept happy through constant consumption of drugs and entertainment. Sex is encouraged and considered casual rather than emotional or intimate. Children are created in laboratories and raised by the state to fulfill predetermined roles.\\n\\nAs John becomes exposed to this new way of life, he begins to question its morality and longs for true human connection. However, his attempts at rebellion ultimately lead to tragedy as he clashes with the powerful leaders of this society.\\n\\nThrough vivid descriptions of technology-driven lifestyles devoid of emotion or individuality, Huxley paints a bleak picture of what could happen if humanity sacrifices freedom for stability and pleasure. Brave New World serves as a cautionary tale about the dangers of sacrificing personal liberties for societal control.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askChatGPT(\"Please summarize Brave new World be Aldus Huxley\", temperature=0.2, frequency_penalty=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brave New World by Aldus Huxley is typically considered appropriate for high school students, specifically in grades 11 and 12. It may also be suitable for advanced or honors English classes in earlier grades.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askChatGPT(\"For which grade in the US would brave new world by Aldus Huxley be appropriate reading material?\", temperature=0.2, frequency_penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 10. Mental Health Issues\n",
      "\n",
      "1. Animal Abuse - 2\n",
      "2. Sexual Violence - 4\n",
      "3. Body Image/Disordered Eating - 1\n",
      "4. Self-Harm/Suicide - 5\n",
      "5. Discrimination/Hate Crimes - 6\n",
      "6. Violence & Graphic Content - 8\n",
      "7. Substance Abuse/Addiction - 7\n",
      "8. Child Abuse/Domestic Violence - 9 \n",
      "9.Homicide/Gun Violence-10 \n",
      "10.Mental Health Issues-5\n"
     ]
    }
   ],
   "source": [
    "r = askChatGPT(\"On a level of 1 to 10, evaluate Brave new world by Aldus Huxley for each of these types of content warning: 1. Animal Abuse, 2. Sexual Violence, 3. Body Image/Disordered Eating, 4. Self-Harm/Suicide, 5. Discrimination/Hate Crimes, 6. Violence & Graphic Content, 7. Substance Abuse/Addiction, 8. Child Abuse/Domestic Violence, 9. Homicide/Gun Violence\", temperature=0.2, frequency_penalty=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fiction\n",
      "2. Dystopian\n",
      "3. Science Fiction\n",
      "4. Classic Literature\n",
      "5. Satire\n",
      "6. Social Criticism\n",
      "7. Totalitarianism\n",
      "8. Genetic Engineering\n",
      "9. Mind Control\n",
      "10. Utopia\n",
      "11. Futuristic Society\n",
      "12. Psychological Manipulation\n",
      "13. Government Control\n",
      "14. Propaganda\n",
      "15. Individualism vs. Conformity\n"
     ]
    }
   ],
   "source": [
    "r = askChatGPT(\"What are the main tags would a bookseller use for brave new world by Aldus Huxley?\", temperature=0.2, frequency_penalty=0.1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"1984\" by George Orwell - This dystopian classic explores themes of government control, surveillance, and individual freedom. Content warning: violence, torture, and sexual content.\n",
      "\n",
      "2. \"Fahrenheit 451\" by Ray Bradbury - Set in a future where books are banned and burned, this novel follows a fireman who begins to question the society he lives in. Content warning: violence and censorship.\n",
      "\n",
      "3. \"The Giver\" by Lois Lowry - In a seemingly perfect society, a young boy is chosen to receive memories of the past and discovers the dark secrets behind their utopian world. Content warning: euthanasia and violence.\n",
      "\n",
      "4. \"The Handmaid's Tale\" by Margaret Atwood - In a society where women's rights have been stripped away, a handmaid must navigate a dangerous world to survive. Content warning: sexual violence and oppression.\n",
      "\n",
      "5. \"The Maze Runner\" by James Dashner - A group of teenagers must navigate a deadly maze while trying to uncover the truth about their existence in this action-packed dystopian novel. Content warning: violence and death.\n"
     ]
    }
   ],
   "source": [
    "print(askChatGPT(\"Suggest 5 books similar to brave new world by Aldus Huxley that are suitable for 9th grade US students. List any content warning for them\", temperature=0.2, frequency_penalty=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import scrolledtext\n",
    "import openai\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual OpenAI API key\n",
    "api_key = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Function to generate a response and update the GUI\n",
    "def generate_response():\n",
    "    question_prompt = input_text.get(\"1.0\", \"end-1c\")\n",
    "    if not question_prompt:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a book title to search.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = askChatGPT(question_prompt)\n",
    "        output_text.delete(\"1.0\", \"end\")\n",
    "        output_text.insert(\"1.0\", response)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "# Function to interact with OpenAI API\n",
    "def askChatGPT(question_prompt, temperature=0.2, frequency_penalty=0.25):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=question_prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=temperature,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        n=1\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Create the tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Book Content Rating Search\")\n",
    "\n",
    "# Create input text box\n",
    "input_label = tk.Label(root, text=\"Enter a book title to search:\")\n",
    "input_label.pack()\n",
    "input_text = scrolledtext.ScrolledText(root, width=50, height=5)\n",
    "input_text.pack()\n",
    "\n",
    "# Create button to generate response\n",
    "generate_button = tk.Button(root, text=\"Generate Response\", command=generate_response)\n",
    "generate_button.pack()\n",
    "\n",
    "# Create output text box\n",
    "output_label = tk.Label(root, text=\"Response:\")\n",
    "output_label.pack()\n",
    "output_text = scrolledtext.ScrolledText(root, width=50, height=10)\n",
    "output_text.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import openai\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual OpenAI API key\n",
    "api_key = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Function to generate ratings based on user inputs\n",
    "def generate_ratings():\n",
    "    book_title = book_title_entry.get()\n",
    "    if not book_title:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a book title.\")\n",
    "        return\n",
    "\n",
    "    # Collect selected parameters\n",
    "    selected_parameters = []\n",
    "    for param, var in parameters_vars.items():\n",
    "        if var.get():\n",
    "            selected_parameters.append(param)\n",
    "\n",
    "    if not selected_parameters:\n",
    "        messagebox.showerror(\"Error\", \"Please select at least one parameter.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Generate a question prompt based on selected parameters\n",
    "        question_prompt = f\"Rate the book '{book_title}' for the following parameters: {', '.join(selected_parameters)}\"\n",
    "        response = askChatGPT(question_prompt)\n",
    "        result_text.delete(\"1.0\", \"end\")\n",
    "        result_text.insert(\"1.0\", response)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "# Function to interact with OpenAI API\n",
    "def askChatGPT(question_prompt, temperature=0.2, frequency_penalty=0.25):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=question_prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=temperature,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        n=1\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Create the tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Book Ratings GUI\")\n",
    "\n",
    "# Create input for book title\n",
    "book_title_label = tk.Label(root, text=\"Enter the book title:\")\n",
    "book_title_label.pack()\n",
    "book_title_entry = tk.Entry(root, width=50)\n",
    "book_title_entry.pack()\n",
    "\n",
    "# Create checkboxes for parameters\n",
    "parameters_vars = {}\n",
    "parameters_label = tk.Label(root, text=\"Select parameters to rate the book:\")\n",
    "parameters_label.pack()\n",
    "\n",
    "parameters = [\n",
    "    \"Animal Abuse\",\n",
    "    \"Sexual Violence\",\n",
    "    \"Body Image/Disordered Eating\",\n",
    "    \"Self-Harm/Suicide\",\n",
    "    \"Discrimination/Hate Crimes (Racism/Sexism/Homophobia)\",\n",
    "    \"Violence & Graphic Content\",\n",
    "    \"Substance Abuse/Addiction\",\n",
    "    \"Child Abuse/Domestic Violence\",\n",
    "    \"Homicide/Gun Violence\"\n",
    "]\n",
    "\n",
    "for param in parameters:\n",
    "    parameters_vars[param] = tk.IntVar()\n",
    "    checkbox = tk.Checkbutton(root, text=param, variable=parameters_vars[param])\n",
    "    checkbox.pack()\n",
    "\n",
    "# Create button to generate ratings\n",
    "generate_button = tk.Button(root, text=\"Generate Ratings\", command=generate_ratings)\n",
    "generate_button.pack()\n",
    "\n",
    "# Create text box for displaying ratings\n",
    "result_label = tk.Label(root, text=\"Ratings:\")\n",
    "result_label.pack()\n",
    "result_text = tk.Text(root, width=50, height=10)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
